"""===========================
motif_analysis.py
===========================

Overview
========

This pipeline computes conversion Rate from fastq SLAM-seq data

files :file:``pipeline.yml` and :file:`conf.py`.

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.yml` file.
CGATReport report requires a :file:`conf.py` and optionally a
:file:`cgatreport.ini` file (see :ref:`PipelineReporting`).

Default configuration files can be generated by executing:

   python <srcdir>/motif_analysis.py config

Input files
-----------

Inputs:

1. STREME inputs
   halflife|residual_lowstab|highstab.bed : bed files consisting of 3'UTR
   sequences of transcript with highest or lowest half-lives or residuals.
2. HOMER inputs
   halflife|residual_lowstab|highstab.bed : bed files consisting of 3'UTR
   sequences of transcript with highest or lowest half-lives or residuals.
   backgroud.bed : bed file consisting of all 3'UTR sequences of transcript
   detected by the pipeline_slamdunk_umis.
3. fire
   fire.bed : bed file consisting of all 3'UTR sequences with a length >6 and
   <10000
   fire_residual|halflife.txt : transcript id and halflife|residual table


The pipeline configuration file pipeline.yml.

Requirements
------------

On top of the default CGAT setup, the pipeline requires the following
* Software:
    - python (v3.8.12 with pysam v0.17.0 when built)
    - meme (v5.3.0 when built)
    - HOMER in path (command findMotifs.pl in path)
* R modules:
   - optparse
   - stringr
   - tools


Pipeline output
===============

final_motifs directory with lowstab and histab motif list

Code
====

"""

import sys
import os
import sqlite3
import csv
import re
import glob
import pandas
import shutil

from cgatcore import pipeline as P
from cgatcore import experiment as E
from ruffus.combinatorics import *

import cgat.GTF as GTF
import cgatcore.iotools as IOTools
from ruffus import *
from cgat.MEME import MemeMotifFile, MotifCluster
import PipelineTomtom

#Load config file options
PARAMS = P.get_parameters(
    ["%s/pipeline.yml" % os.path.splitext(__file__)[0],
     "../pipeline.yml",
     "pipeline.yml"])
########################

@transform("*.bed",
           regex("(.+).bed"),
           r"\1.fasta")
def getfasta(infile, outfile):
    '''From most and less stable bed file, get sequences and generate fasta for streme'''
    genome_file = os.path.abspath(os.path.join(PARAMS["genome_dir"], PARAMS["genome"] + ".fa"))
    statement = '''
    bedtools getfasta -bed %(infile)s
    -fi %(genome_file)s
    -fo %(outfile)s
    -nameOnly
    '''
    P.run(statement)

#STREME
@subdivide(getfasta,
           regex("(.+)_highstab.fasta"),
           add_inputs(r"\1_lowstab.fasta"),
           [r"\1_highstab_streme.dir/streme.txt",
            r"\1_lowstab_streme.dir/streme.txt"])
def streme(infiles, outfiles):
    '''STREME motif enrichment motif_analysis
    https://meme-suite.org/meme/doc/streme.html?man_type=web'''
    highstab, lowstab = infiles
    highout, lowout = outfiles
    highout = P.snip(highout, "/streme.txt")
    lowout = P.snip(lowout, "/streme.txt")
    eval = PARAMS["e_value"]
    min = PARAMS["min_motif_width"]
    max = PARAMS["max_motif_width"]
    statement = '''
    streme --p %(highstab)s
    --n %(lowstab)s
    --minw %(min)s --maxw %(max)s --rna
    --thresh %(eval)s
    --evalue %(eval)s
    --patience 0
    --oc %(highout)s
    '''
    statement2 = '''
    streme --p %(lowstab)s
    --n %(highstab)s
    --minw %(min)s --maxw %(max)s --rna
    --thresh %(eval)s
    --evalue %(eval)s
    --patience 0
    --oc %(lowout)s
    '''
    P.run([statement,  statement2],
    job_memory="6G",
    job_threads=1)


#HOMER
@transform(getfasta,
           regex("(.+)_(highstab|lowstab).fasta"),
           add_inputs("background.fasta"),
           r"\1_\2_homer.dir/homerMotifs.all.motifs")
def homer(infiles, outfile):
    '''HOMER motif enrichment analysis
    http://homer.ucsd.edu/homer/motif/fasta.html'''
    stab, bg = infiles
    out = P.snip(outfile, "homerMotifs.all.motifs")
    length = PARAMS["motif_sizes"]
    statement = '''
    findMotifs.pl %(stab)s fasta %(out)s
    -fasta %(bg)s -rna -len %(length)s
    -noknown -noweight -nogo -fdr 100 -p 8
    '''
    P.run(statement ,
    job_memory="8G",
    job_threads=6)

#FIRE
@follows(getfasta)
@subdivide(["fire_halflife.txt","fire_residual.txt"],
       formatter(),
       add_inputs("fire.fasta"),
       [r"{path[0]}/{basename[0]}.txt.%imer_FIRE/RNA/{basename[0]}.txt.%imer.signif.motifs.rep" % (i,i) for i in range(6,9)])
       #"{path[0]}/{basename[0]}.txt_FIRE/RNA/{basename[0]}.txt.*.signif.motifs.rep")
       #[r"\1_FIRE/RNA/\1%imer.signif.motifs.rep" % i for i in range(6,8)])
def fire(infiles, outfiles):
    '''FIRE : https://tavazoielab.c2b2.columbia.edu/FIRE/tutorial.html
    When searching for RNA motifs (typically in 3â€™UTRs), FIRE examines all
    16,384 7-mers ad esempio. For each  k-mer,  the  mutual  information
    between  its  profile  and  the  expression  profile  is evaluated. All
    k-mers are then sorted based on their information values and a simple and
    information is not significant, within the sorted list. All k-mers sorted
    above these 10 are retained  for  further  analysis,  and  are  henceforth
    termed  motif  seeds.  Recall,  that  the information  associated  with
    a  particular  k-mer  is  considered  significant  if  and  only  if  it
    passes  the  randomization  test,  i.e.,  if  it  is  greater  than  all
    Nr  random  information  values obtained for this k-mer profile over Nr
    randomly shuffled expression profiles. To correct for  multiple  hypothesis
    testing,  Nr  is  set  by  default  to  the  number  of  k-mers  initially
    examined'''
    expression, fasta = infiles
    expression = os.path.join(os.getcwd()+"/"+expression)
    fasta = os.path.join(os.getcwd()+"/"+fasta)

    statements = list()
    for kmer in range(6,9):
        ikmer = str(kmer)+"mer"
        statement = '''
        module load bio/fire &&
        fire --expfiles=%(expression)s
        --exptype=continuous
        --fastafile_rna=%(fasta)s
        --nodups=1 --k=%(kmer)s
        --suffix=%(ikmer)s
        --dodna=0 --dodnarna=0
        --oribiasonly=0
        ''' % locals()
        statements.append(statement)
        P.run(statements,
        job_memory="8G",
        job_threads=1)


@follows(getfasta)
@transform(["background.fasta", "fire.fasta"],
           regex("(.+)"),
           r"\1.bg")
def fasta_to_bg(infile, outfile):
    '''Get markov bg for fasta'''
    statement = '''
    fasta-get-markov %(infile)s > %(outfile)s
    '''
    P.run(statement)

#HOMER conversion
@follows(fasta_to_bg)
@transform(homer,
           regex("(.+)_(highstab|lowstab)_homer.dir/homerMotifs.all.motifs"),
           add_inputs("background.fasta.bg"),
           r"\1_\2_homer.dir/homerMotifs.all.motifs.meme")
def homer_to_meme(infiles, outfile):
    '''Convert HOMER output to MEME format for tomtom'''
    homer_file, background = infiles
    #out_dir = P.snip(outfile, "/homerMotifs.all.motifs.meme")
    script_path = os.path.join((os.path.dirname(__file__)),
                               "Rscripts",
                               "homer2meme.R")
    fdr_thresh = length = PARAMS["fdr"]
    statement = '''
    Rscript %(script_path)s
    -i %(homer_file)s
    -b %(background)s
    -t %(fdr_thresh)s
    '''
    P.run(statement)

#Fire merge and conversion
@subdivide(fire,
       regex("(.+)txt.([0-9]mer).signif.motifs.rep"),
       [r"\1\2_highstab.signif.motifs", r"\1\2_lowstab.signif.motifs"])
def extractFire (infile, outfiles):
    '''Extract significant motifs from FIRE enriched in top or bottom bin'''
    script_path = os.path.join((os.path.dirname(__file__)),
                               "Rscripts",
                               "extract_fire_motifs.R")
    statement = '''
    Rscript %(script_path)s
    -f %(infile)s
    '''
    P.run(statement)

#fire_halflife.6mer_highstab.signif.motifs


@follows(mkdir("fire.dir"))
@collate(extractFire,
        regex(r"fire_(halflife|residual).txt.(?:[0-9]mer).+([0-9]mer)_(highstab|lowstab).signif.motifs"),
        r"fire.dir/\1_\3.allkmer.signif.motifs")
def mergeFireKmers(infiles, outfile):
    '''Merge the fire kmer results together'''
    input_string = " ".join(infiles)
    statement= '''
    cat %(input_string)s > %(output)s
    '''
    P.run(statement)


@follows(fasta_to_bg)
@transform(mergeFireKmers,
           regex("(.+)"),
           add_inputs("fire.fasta.bg"),
           r"\1.meme")
def fire_to_meme(infiles, outfile):
    '''Convert FIRE output to MEME format for tomtom'''
    fire_file, background = infiles
    fire_temp = fire_file+".temp"
    script_path = os.path.join((os.path.dirname(__file__)),
                               "Rscripts",
                               "fire2meme.R")
    statement = '''
    while read -r line;
    do iupac2meme $line -bg %(background)s ;
    done < %(fire_file)s > %(fire_temp)s &&
    Rscript %(script_path)s
    -i %(fire_temp)s
    -b %(background)s &&
    rm %(fire_temp)s
    '''
    P.run(statement)

#Self Tomtom for Homer, Fire and Streme results
@transform([streme,homer_to_meme,fire_to_meme],
       regex("(.+)(meme|streme\.txt)"),
       r"\1tomtom.self")
def tomtom_self(infile, outfile):
    '''Self tomtom on motif files'''
    if (infile.count("streme.txt") >= 1) and (IOTools.get_num_lines(infile) <= 38):
        E.warn("No motifs - no computation performed")
        IOTools.touch_file(outfile)
        return
    if (infile.count("streme.txt") == 0) and (IOTools.get_num_lines(infile) <= 9):
        E.warn("No motifs - no computation performed")
        IOTools.touch_file(outfile)
        return
    tomtom_file = infile+".tomtom"
    tomtom_log = tomtom_file+".log"
    e_val = PARAMS["thresh_self"]
    statement = '''
    tomtom -verbosity 1 -text -norc -thresh %(e_val)s
    %(infile)s %(infile)s
    2> %(tomtom_log)s | sed 's/#//' > %(tomtom_file)s
    '''
    P.run(statement, job_options = "-P gen2reg -l h_rt=1:00:00")
    PipelineTomtom.getSeedMotifs(infile, tomtom_file, outfile)
    statement = '''
    rm %(tomtom_file)s
    '''
    P.run(statement)

@follows(mkdir("final_motifs"))
@collate([streme,homer_to_meme,fire_to_meme],
         regex(".*(lowstab|highstab).+"),
         add_inputs("background.fasta.bg"),
         r"final_motifs/\1_final_motifs.meme")
def tomtom_combine(infiles, outfile):
    '''Merge all motifs together, than run tomtom the merge and eliminate
    redudannt motifs to create the final list of motifs'''
    motif_files, background = infiles
    if len(motif_files) == 0:
        return
    if len(motif_files) == 1:
        statement = '''
        mv %(motif_files)s %(outfile)s
        '''
        return

    input_string = " ".join(motif_files)
    temp_file = P.snip(outfile, "final_motifs.meme")+"merged.motifs"
    statement = '''
    meme2meme -bg %(background)s
    %(input_string)s > %(temp_file)s
    '''
    P.run(statement)
    e_val = PARAMS["thresh_merge"]
    tomtom_log = outfile+".log"
    temp_tomtom = P.snip(outfile, "final_motifs.meme")+"merged.motifs.tomtom"
    statement = '''
    tomtom -verbosity 1 -text -norc -thresh %(e_val)s
    %(temp_file)s %(temp_file)s
    2> %(tomtom_log)s | sed 's/#//' > %(temp_tomtom)s
    '''
    P.run(statement)
    PipelineTomtom.getSeedMotifs(temp_file, temp_tomtom, outfile)


# @follows(mkdir("highstab_files", "lowstab_files"))
# @transform(tomtom_self,
#            regex(".*(halflife|residual)_(highstab|lowstab)(.+)tomtom.self"),
#            r"\2_files/\1_\2\3_not_a_directory")
# def renamingAndCluster(infile, outfile):
#     '''Renaming and regrouping all motif files into hoghstab and lowstab
#     directories'''
#     if IOTools.is_empty(infile):
#         return
#
#     if "fire" in infile:
#         out_final = outfile.replace(".signif.motifs._not_a_directory", ".fire")
#         statement = '''
#         mv %(infile)s %(out_final)s
#         '''
#         P.run(statement, job_options = "-P gen2reg -l h_rt=1:00:00")
#     if "homer" in infile:
#         out_final = outfile.replace("_homer.dir/homerMotifs.all.motifs._not_a_directory", ".homer")
#         statement = '''
#         mv %(infile)s %(out_final)s
#         '''
#         P.run(statement, job_options = "-P gen2reg -l h_rt=1:00:00")
#     if "streme" in infile:
#         out_final = outfile.replace("_streme.dir/_not_a_directory", ".streme")
#         statement = '''
#         mv %(infile)s %(out_final)s
#         '''
#         P.run(statement, job_options = "-P gen2reg -l h_rt=1:00:00")
#     # statement = 'rm -r highstab_files/*.dir lowstab_files/*.dir'
#     # P.run(statement)
#
#  ##############################################################################
# @follows(renamingAndCluster)
# def motif_enrichments():
#     '''Later alligator'''
#     pass
#  ##############################################################################
#
#
# @collate(["lowstab_motifs/*","highstab_motifs/*"],
#          regex("(lowstab_motifs/|highstab_motifs/).+"),
#          add_inputs("background.fasta.bg"),
#          r"\1final_motifs.meme")


@transform(tomtom_combine,
           regex("(highstab)(.+)"),
           r"\1\2.mirna.tomtom")
def scan_mirna(infile, outfile):
    '''Scan highstab motifs for miRNAs'''
    tomtom_log = outfile+".log"
    e_val = PARAMS["thresh_mirna"]
    mirna_seeds = PARAMS["mirna_db"]
    statement = '''
    tomtom -verbosity 1 -text -norc -thresh %(e_val)s
    %(infile)s %(mirna_seeds)s
    2> %(tomtom_log)s | sed 's/#//' > %(outfile)s
    '''
    P.run(statement)

# @transform(tomtom_combine,
#            regex("(lowstab)(_.+)"),
#            add_inputs(),
#            r"\1\2.list")
# def extractListMotifs(infile, outfile):
#     '''Create list of motifs for linker generator'''
#     pass



@follows(scan_mirna)
def full():
    '''Later alligator'''
    pass

P.main()
